
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

name: Java CI with Maven

on:
  push:
    branches:
      - alpha
      - beta
      - development
      - master
      - staging
      - tagscanary
      - tagscanarymerge
      - fixlabels
      - interceptapis
      - tags_intg_test
      - nb_tags_intg_test
      - prove-ci-blind-fresh


jobs:
  build:
    runs-on: ubuntu-latest
    if: false  # Temporarily disabled for smoke test development

    steps:
      - uses: actions/checkout@v3

      # Set up Docker
      - name: Set up Docker
        uses: docker/setup-buildx-action@v2
        with:
          driver-opts: image=moby/buildkit:master
          install: true

      - name: Set up JDK 17
        uses: actions/setup-java@v1
        with:
          java-version: 17

      - name: Print JDK version
        run: java -version

      # Verify Docker is available
      - name: Verify Docker
        run: |
         docker --version
         docker info

      - name: Cache Maven packages
        uses: actions/cache@v3
        with:
          path: ~/.m2
          key: ${{ runner.os }}-m2-${{ hashFiles('**/build.sh') }}
          restore-keys: ${{ runner.os }}-m2

      - name: Get branch name
        run: |
          echo "BRANCH_NAME=${GITHUB_REF#refs/heads/}" >> $GITHUB_ENV
          echo BRANCH_NAME=${GITHUB_REF#refs/heads/}

      - name: Create Maven Settings
        uses: s4u/maven-settings-action@v2.8.0
        with:
          servers: |
            [{
                "id": "github",
                "username": "atlan-ci",
                "password": "${{ secrets.ORG_PAT_GITHUB }}"
            }]

      - name: Build with Maven
        run: |
          echo "build without dashboard"
          chmod +x ./build.sh && ./build.sh

      - name: Check disk space before tests
        run: |
          echo "=========================================="
          echo "DISK SPACE CHECK"
          echo "=========================================="
          df -h / | grep -E '^/dev/' || df -h / | tail -1
          echo ""
          
          # Get disk usage percentage (remove % sign)
          DISK_USAGE=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')
          echo "Current disk usage: ${DISK_USAGE}%"
          
          if [ "$DISK_USAGE" -gt 80 ]; then
            echo "Disk usage is high (${DISK_USAGE}%), cleanup required"
          else
            echo "Disk space is adequate (${DISK_USAGE}%)"
          fi

      - name: Free up disk space for tests
        run: |
          echo "=========================================="
          echo "CLEANING UP DISK SPACE"
          echo "=========================================="
          
          # Clean Docker system
          echo "Cleaning Docker system..."
          docker system prune -af --volumes || true
          
          # Clean apt cache
          echo "Cleaning apt cache..."
          sudo apt-get clean || true
          sudo rm -rf /var/cache/apt/archives/* || true
          
          # Clean temp files
          echo "Cleaning temp files..."
          sudo rm -rf /tmp/* || true
          
          # Clean old GitHub Actions logs
          echo "Cleaning GitHub Actions logs..."
          sudo rm -rf /home/runner/work/_temp/_runner_file_commands/* || true
          
          # Clean hostedtoolcache if needed (keep essentials)
          echo "Cleaning hostedtoolcache (non-essential tools)..."
          sudo rm -rf /opt/hostedtoolcache/CodeQL || true
          sudo rm -rf /opt/hostedtoolcache/go || true
          sudo rm -rf /opt/hostedtoolcache/PyPy || true
          sudo rm -rf /opt/hostedtoolcache/node || true
          sudo rm -rf /opt/hostedtoolcache/Ruby || true
          
          echo ""
          echo "Disk space after cleanup:"
          df -h / | grep -E '^/dev/' || df -h / | tail -1

      - name: Verify sufficient disk space
        run: |
          echo "=========================================="
          echo "VERIFYING DISK SPACE"
          echo "=========================================="
          
          DISK_USAGE=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')
          AVAILABLE_GB=$(df -h / | tail -1 | awk '{print $4}')
          
          echo "Current disk usage: ${DISK_USAGE}%"
          echo "Available space: ${AVAILABLE_GB}"
          
          # Fail if disk usage is still above 85%
          if [ "$DISK_USAGE" -gt 85 ]; then
            echo "ERROR: Insufficient disk space (${DISK_USAGE}% used)"
            echo "Tests require at least 15% free space to run reliably"
            echo "Elasticsearch will fail with high disk watermark errors at 90%+"
            exit 1
          else
            echo "Sufficient disk space available (${DISK_USAGE}% used)"
          fi

      - name: Run Integration Tests
        id: integration_tests
        continue-on-error: true
        env:
          # Configure Testcontainers for GitHub Actions
          TESTCONTAINERS_RYUK_DISABLED: true
          TESTCONTAINERS_CHECKS_DISABLE: true
          DOCKER_HOST: unix:///var/run/docker.sock
        run: |
          echo "Running integration tests..."
          chmod +x ./run-integration-tests.sh && ./run-integration-tests.sh
      
      - name: Capture container logs on failure
        if: steps.integration_tests.outcome == 'failure'
        run: |
          echo "=========================================="
          echo "CAPTURING CONTAINER LOGS"
          echo "=========================================="
          
          mkdir -p test-debug-logs
          
          echo "All containers:"
          docker ps -a | tee test-debug-logs/docker-ps.log
          
          echo ""
          echo "Capturing logs..."
          for container in $(docker ps -a --format '{{.Names}}'); do
            echo "Capturing logs for: $container"
            docker logs "$container" > "test-debug-logs/${container}.log" 2>&1 || echo "Failed to get logs for $container"
          done
          
          echo ""
          echo "=========================================="
          echo "PREVIEW: Atlas Container Logs (last 100 lines)"
          echo "=========================================="
          atlas_container=$(docker ps -a --filter "ancestor=atlanhq/atlas:test" --format "{{.Names}}" | head -1)
          if [ -n "$atlas_container" ]; then
            echo "Atlas container: $atlas_container"
            docker logs "$atlas_container" 2>&1 | tail -100 || echo "No Atlas logs available"
          else
            echo "No Atlas container found"
          fi
          
          ls -lh test-debug-logs/
      
      - name: Upload container logs as artifact
        if: steps.integration_tests.outcome == 'failure'
        uses: actions/upload-artifact@v4
        with:
          name: container-logs-${{ github.run_id }}
          path: test-debug-logs/
          retention-days: 5
      
      - name: Setup tmate session on test failure
        if: steps.integration_tests.outcome == 'failure'
        uses: mxschmitt/action-tmate@v3
        timeout-minutes: 30
        with:
          detached: true
          limit-access-to-actor: false
      
      - name: Fail the workflow if tests failed
        if: steps.integration_tests.outcome == 'failure'
        run: exit 1

      - name: Clean up after integration tests
        run: |
          echo "=========================================="
          echo "CLEANING UP AFTER INTEGRATION TESTS"
          echo "=========================================="
          
          # Remove test containers and images
          echo "Removing test containers and images..."
          docker system prune -af --volumes || true
          
          # Clean Maven artifacts to free up space
          echo "Cleaning Maven artifacts..."
          rm -rf ~/.m2/repository/org/apache/atlas/ || true
          
          # Clean test artifacts
          echo "Cleaning test artifacts..."
          rm -rf webapp/target/surefire-reports/ || true
          rm -rf test-debug-logs/ || true
          
          # Clean temp files
          echo "Cleaning temp files..."
          sudo rm -rf /tmp/* || true
          
          echo ""
          echo "Disk space after cleanup:"
          df -h / | tail -1

      - name: Get Repository Name
        run:   echo "REPOSITORY_NAME=`echo "$GITHUB_REPOSITORY" | awk -F / '{print $2}' | sed -e "s/:refs//"`" >> $GITHUB_ENV
        shell: bash

      - name: Get version tag
        # run: echo "##[set-output name=version;]$(echo `git ls-remote https://${{ secrets.ORG_PAT_GITHUB }}@github.com/atlanhq/${REPOSITORY_NAME}.git ${{ env.BRANCH_NAME }} | awk '{ print $1}' | cut -c1-7`)abcd"
        run: |
          echo "VERSION=$(git ls-remote https://${{ secrets.ORG_PAT_GITHUB }}@github.com/atlanhq/${REPOSITORY_NAME}.git ${{ env.BRANCH_NAME }} | awk '{ print $1}' | cut -c1-7 | head -n 1)abcd"
          echo "VERSION=$(git ls-remote https://${{ secrets.ORG_PAT_GITHUB }}@github.com/atlanhq/${REPOSITORY_NAME}.git ${{ env.BRANCH_NAME }} | awk '{ print $1}' | cut -c1-7 | tr -d '[:space:]')abcd"
          echo "VERSION=$(git ls-remote https://${{ secrets.ORG_PAT_GITHUB }}@github.com/atlanhq/${REPOSITORY_NAME}.git ${{ env.BRANCH_NAME }} | awk '{ print $1}' | cut -c1-7 | tr -d '[:space:]')abcd" >> $GITHUB_ENV

      - name: Get commit ID
        run: echo "COMMIT_ID=$(echo ${GITHUB_SHA} | cut -c1-7)abcd" >> $GITHUB_ENV

      # QEMU is required to build arm from a non-arm build machine
      - name: Set up QEMU
        id: qemu
        uses: docker/setup-qemu-action@v3
        with:
          image: tonistiigi/binfmt:qemu-v7.0.0-28
          platforms: arm64

      - name: Set up Buildx
        id: buildx
        uses: docker/setup-buildx-action@v1

      - name: Login to GitHub Registry
        uses: docker/login-action@v1
        with:
          registry: ghcr.io
          username: $GITHUB_ACTOR
          password: ${{ secrets.ORG_PAT_GITHUB }}

      - name: Build and push
        id: docker_build
        uses: docker/build-push-action@v3
        with:
          platforms: linux/amd64,linux/arm64
          context: .
          file: ./Dockerfile
          no-cache: true
          sbom: true
          provenance: true
          push: true
          tags: |
            ghcr.io/atlanhq/${{ github.event.repository.name }}-${{ env.BRANCH_NAME }}:latest
            ghcr.io/atlanhq/${{ github.event.repository.name }}-${{ env.BRANCH_NAME }}:${{ env.COMMIT_ID }}

      - name: Check Image Manifest
        run: docker buildx imagetools inspect --raw ghcr.io/atlanhq/${{ github.event.repository.name }}-${{ env.BRANCH_NAME }}:${{ env.COMMIT_ID }}

      - name: Scan Image
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'ghcr.io/atlanhq/${{ github.event.repository.name }}-${{ env.BRANCH_NAME }}:${{ env.COMMIT_ID }}'
          vuln-type: 'os,library'
          format: 'sarif'
          output: 'trivy-image-results.sarif'

      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v2.1.33
        with:
          sarif_file: 'trivy-image-results.sarif'

  # Smoke test on vclusters (parallel with single VPN)
  smoke-test:
    name: Multi-Cloud Smoke Test
    # needs: build  # Disabled while build job is disabled
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      
      - name: Set test image (hardcoded for testing)
        run: echo "TEST_IMAGE=ghcr.io/atlanhq/atlas-metastore-prove-ci-blind-fresh:064f482abcd" >> $GITHUB_ENV
      
      - name: Install kubectl
        uses: azure/setup-kubectl@v3
      
      - name: Install vCluster CLI
        uses: loft-sh/setup-vcluster@main
      
      - name: Install jq
        run: sudo apt-get install -y jq
      
      - name: Connect to GlobalProtect VPN
        env:
          VCLUSTER_PLATFORM_URL: ${{ secrets.VCLUSTER_PLATFORM_URL }}
        run: |
          echo "=================================================="
          echo "CONNECTING TO VPN (Shared for all clouds)"
          echo "=================================================="
          
          # Install OpenConnect
          sudo apt-get update -qq
          sudo apt-get install -y openconnect
          
          # Connect to VPN (using default DTLS/ESP for AWS compatibility)
          echo "${{ secrets.GLOBALPROTECT_PASSWORD }}" | sudo openconnect \
            --protocol=gp \
            --user="${{ secrets.GLOBALPROTECT_USERNAME }}" \
            --passwd-on-stdin \
            --background \
            "${{ vars.GLOBALPROTECT_PORTAL_URL }}"
          
          # Wait for connection to establish
          echo "Waiting for VPN connection to stabilize..."
          sleep 20
          
          # Check if VPN is running
          if ! pgrep -x openconnect > /dev/null; then
            echo "ERROR: OpenConnect exited unexpectedly"
            exit 1
          fi
          echo "VPN process is running (PID: $(pgrep -x openconnect))"
          
          # Configure routing for vCluster Platform (172.17.0.0/16)
          VPN_INTERFACE=$(ip addr show | grep -E '^[0-9]+: tun' | head -1 | cut -d: -f2 | tr -d ' ' || echo "tun0")
          echo "Using VPN interface: $VPN_INTERFACE"
          
          sudo ip route del 172.17.0.0/16 dev docker0 2>/dev/null || true
          sudo ip route add 172.17.0.0/16 dev $VPN_INTERFACE
          
          # Verify connectivity
          if curl -k -sS $VCLUSTER_PLATFORM_URL -o /dev/null --max-time 30; then
            echo "✓ VPN connected successfully"
          else
            echo "ERROR: VPN connectivity test failed"
            exit 1
          fi
      
      - name: Login to vCluster Platform
        env:
          VCLUSTER_PLATFORM_URL: ${{ secrets.VCLUSTER_PLATFORM_URL }}
          VCLUSTER_ACCESS_KEY: ${{ secrets.VCLUSTER_ACCESS_KEY }}
        run: |
          echo "=================================================="
          echo "LOGGING IN TO VCLUSTER PLATFORM (Shared)"
          echo "=================================================="
          vcluster platform login $VCLUSTER_PLATFORM_URL --access-key $VCLUSTER_ACCESS_KEY
          echo "✓ Login successful"
      
      - name: Connect to all vClusters
        run: |
          echo "=================================================="
          echo "CONNECTING TO ALL VCLUSTERS"
          echo "=================================================="
          
          # Connect to AWS vCluster
          echo "Connecting to AWS vCluster (hkmeta02)..."
          vcluster platform connect vcluster hkmeta02 --project default --print-kube-config > kubeconfig-aws.yaml
          echo "✓ AWS kubeconfig saved"
          
          # Connect to Azure vCluster  
          echo "Connecting to Azure vCluster (enpla1cp21)..."
          vcluster platform connect vcluster enpla1cp21 --project default --print-kube-config > kubeconfig-azure.yaml
          echo "✓ Azure kubeconfig saved"
          
          echo ""
          echo "All vCluster connections established"
      
      - name: Run parallel smoke tests
        run: |
          echo "=================================================="
          echo "STARTING PARALLEL SMOKE TESTS"
          echo "=================================================="
          
          # Create logs directory
          mkdir -p smoke-test-logs
          
          # Define test function
          test_cloud() {
            CLOUD=$1
            KUBECONFIG_FILE=$2
            LOG_FILE="smoke-test-logs/${CLOUD}.log"
            
            {
              echo "=========================================="
              echo "[${CLOUD}] Starting smoke test"
              echo "=========================================="
              echo "Image: $TEST_IMAGE"
              echo "Kubeconfig: $KUBECONFIG_FILE"
              echo ""
              
              # Patch deployment
              echo "[${CLOUD}] Patching Atlas deployment..."
              if ! KUBECONFIG=$KUBECONFIG_FILE kubectl set image deployment/atlas \
                atlas-main=$TEST_IMAGE \
                -n atlas; then
                echo "[${CLOUD}] ERROR: Failed to patch deployment"
                exit 1
              fi
              echo "[${CLOUD}] ✓ Deployment patched"
              echo ""
              
              # Wait for rollout
              echo "[${CLOUD}] Waiting for rollout (10 min timeout)..."
              if KUBECONFIG=$KUBECONFIG_FILE kubectl rollout status deployment/atlas -n atlas --timeout=10m; then
                echo "[${CLOUD}] ✓ Rollout completed successfully"
              else
                echo "[${CLOUD}] ERROR: Rollout failed or timed out"
                echo "[${CLOUD}] Pod status:"
                KUBECONFIG=$KUBECONFIG_FILE kubectl get pods -n atlas -l app=atlas
                echo "[${CLOUD}] Recent events (excluding Normal):"
                KUBECONFIG=$KUBECONFIG_FILE kubectl get events -n atlas --sort-by='.lastTimestamp' | grep -v "Normal" | tail -20
                exit 1
              fi
              echo ""
              
              # Port-forward and test
              echo "[${CLOUD}] Setting up port-forward..."
              # Use unique port per cloud to avoid conflicts
              if [ "$CLOUD" = "AWS" ]; then
                LOCAL_PORT=21001
              elif [ "$CLOUD" = "Azure" ]; then
                LOCAL_PORT=21002
              else
                LOCAL_PORT=21003
              fi
              
              KUBECONFIG=$KUBECONFIG_FILE kubectl port-forward -n atlas svc/atlas-service-atlas $LOCAL_PORT:80 > /dev/null 2>&1 &
              PF_PID=$!
              sleep 5
              
              # Status check
              echo "[${CLOUD}] Running status check..."
              STATUS_RESPONSE=$(curl -f -s "http://localhost:$LOCAL_PORT/api/atlas/admin/status")
              if [ $? -eq 0 ]; then
                STATUS=$(echo "$STATUS_RESPONSE" | jq -r '.Status')
                if [ "$STATUS" = "ACTIVE" ]; then
                  echo "[${CLOUD}] ✓ Atlas is ACTIVE"
                else
                  echo "[${CLOUD}] ERROR: Status check failed - Status: $STATUS"
                  kill $PF_PID 2>/dev/null || true
                  exit 1
                fi
              else
                echo "[${CLOUD}] ERROR: Could not reach endpoint"
                kill $PF_PID 2>/dev/null || true
                exit 1
              fi
              
              # Cleanup
              kill $PF_PID 2>/dev/null || true
              
              echo ""
              echo "[${CLOUD}] ✓✓✓ SMOKE TEST PASSED ✓✓✓"
              echo ""
            } > "$LOG_FILE" 2>&1
          }
          
          # Export variables for subshells
          export TEST_IMAGE=${{ env.TEST_IMAGE }}
          export -f test_cloud
          
          # Start tests in parallel
          echo "Launching AWS test..."
          bash -c "test_cloud AWS kubeconfig-aws.yaml" &
          PID_AWS=$!
          
          echo "Launching Azure test..."
          bash -c "test_cloud Azure kubeconfig-azure.yaml" &
          PID_AZURE=$!
          
          echo ""
          echo "Both tests running in parallel..."
          echo "AWS PID: $PID_AWS"
          echo "Azure PID: $PID_AZURE"
          echo ""
          
          # Tail logs in real-time (interleaved)
          tail -f smoke-test-logs/AWS.log 2>/dev/null | sed 's/^/[AWS-LOG] /' &
          TAIL_AWS=$!
          tail -f smoke-test-logs/Azure.log 2>/dev/null | sed 's/^/[Azure-LOG] /' &
          TAIL_AZURE=$!
          
          # Wait for tests to complete
          FAILED=0
          
          if wait $PID_AWS; then
            echo "✓ AWS test completed successfully"
          else
            echo "✗ AWS test failed"
            FAILED=1
          fi
          
          if wait $PID_AZURE; then
            echo "✓ Azure test completed successfully"
          else
            echo "✗ Azure test failed"
            FAILED=1
          fi
          
          # Stop tailing logs
          kill $TAIL_AWS $TAIL_AZURE 2>/dev/null || true
          
          # Show final summary
          echo ""
          echo "=================================================="
          echo "SMOKE TEST RESULTS"
          echo "=================================================="
          cat smoke-test-logs/AWS.log | tail -5
          echo ""
          cat smoke-test-logs/Azure.log | tail -5
          echo "=================================================="
          
          # Exit with failure if any test failed
          if [ $FAILED -eq 1 ]; then
            echo "ERROR: One or more smoke tests failed"
            exit 1
          fi
          
          echo "✓ All smoke tests passed!"
      
      - name: Upload smoke test logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-test-logs-${{ github.run_id }}
          path: smoke-test-logs/
          retention-days: 5